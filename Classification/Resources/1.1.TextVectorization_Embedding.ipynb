{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea658f50",
   "metadata": {},
   "source": [
    "## TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3ee1e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ad970db",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1 = 'We are learning AI'\n",
    "sample2 = 'AI is a CS topic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f9906c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 8\n",
    "sequence_length = 5\n",
    "\n",
    "vectorize_layer = TextVectorization(max_tokens=vocab_size,\n",
    "                                    output_mode=\"int\",\n",
    "                                    output_sequence_length=sequence_length)\n",
    "\n",
    "vectorize_layer.adapt([sample1, sample2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dc40df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '[UNK]', 'ai', 'we', 'topic', 'learning', 'is', 'cs']\n"
     ]
    }
   ],
   "source": [
    "vocabs = vectorize_layer.get_vocabulary()\n",
    "print(vocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a14497f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([3 1 5 2 0], shape=(5,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "sample1_vector = vectorize_layer('We are learning AI')\n",
    "print(sample1_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0559a7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2 6 1 7 4], shape=(5,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "sample2_vector = vectorize_layer('AI is a CS topic')\n",
    "print(sample2_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4df552ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([5 2 6 1 0], shape=(5,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "test_vector = vectorize_layer('Learning AI is difficult!')\n",
    "print(test_vector) #???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba508d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b27673a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '', 1: '[UNK]', 2: 'ai', 3: 'we', 4: 'topic', 5: 'learning', 6: 'is', 7: 'cs'}\n"
     ]
    }
   ],
   "source": [
    "# decode\n",
    "\n",
    "index_vocab = {i: v for i, v in enumerate(vocabs)}\n",
    "print(index_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b088fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 2, 6, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "a_vector = [5, 2, 6, 1, 0]\n",
    "print(a_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "837d80af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['learning', 'ai', 'is', '[UNK]', '']\n"
     ]
    }
   ],
   "source": [
    "text = [index_vocab[i] for i in a_vector]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcf8f8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7622797",
   "metadata": {},
   "source": [
    "## Using [Start] Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee2aa325",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 4\n",
    "vocab_size = 8\n",
    "sequence_length = 5\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "layer = Embedding(vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7232430b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[4. 3. 1. 5. 4.]], shape=(1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a_vector = [[4., 3.0, 1.0, 5.0, 4.0]]\n",
    "a_vector = tf.convert_to_tensor(a_vector)\n",
    "print(a_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de48205f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-0.02545398 -0.01913146  0.01199605 -0.03054712]\n",
      "  [ 0.03966483 -0.01925439  0.0141543   0.0195548 ]\n",
      "  [ 0.03752751  0.01604519  0.03197367 -0.01292641]\n",
      "  [-0.01600847 -0.02929524  0.01094943  0.03886148]\n",
      "  [-0.02545398 -0.01913146  0.01199605 -0.03054712]]], shape=(1, 5, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "output = layer(a_vector)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "091bc427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'embedding/embeddings:0' shape=(8, 4) dtype=float32, numpy=\n",
       "array([[ 0.04684255, -0.00200953, -0.04727422,  0.00881772],\n",
       "       [ 0.03752751,  0.01604519,  0.03197367, -0.01292641],\n",
       "       [-0.00208209,  0.03913813,  0.0018545 ,  0.01120707],\n",
       "       [ 0.03966483, -0.01925439,  0.0141543 ,  0.0195548 ],\n",
       "       [-0.02545398, -0.01913146,  0.01199605, -0.03054712],\n",
       "       [-0.01600847, -0.02929524,  0.01094943,  0.03886148],\n",
       "       [-0.02353916, -0.04173622,  0.01859237, -0.00422686],\n",
       "       [-0.02809455, -0.03801959,  0.04050454,  0.02462274]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559aaee1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
