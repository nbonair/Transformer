{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ebd0c51",
   "metadata": {},
   "source": [
    "## Download and pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f70a707",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7610f920",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "\n",
    "dataset = tf.keras.utils.get_file(\"aclImdb_v1.tar.gz\", url,\n",
    "                                  untar=True, cache_dir='.',\n",
    "                                  cache_subdir='')\n",
    "\n",
    "dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\n",
    "os.listdir(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc0ab10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f54bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(dataset_dir, 'train')\n",
    "os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c68e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_dir = os.path.join(train_dir, 'unsup')\n",
    "shutil.rmtree(remove_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33f6b55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f55c2db",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e65740b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f65d5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 20000 files for training.\n",
      "Found 25000 files belonging to 2 classes.\n",
      "Using 5000 files for validation.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "seed = 12345\n",
    "train_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "                            'aclImdb/train', batch_size=batch_size, \n",
    "                            validation_split=0.2,\n",
    "                            subset='training', seed=seed)\n",
    "val_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "                            'aclImdb/train', batch_size=batch_size, \n",
    "                            validation_split=0.2,\n",
    "                            subset='validation', seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2846310e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1849e8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "b\"The first von Trier movie i've ever seen was breaking the waves. Sure a nice movie but it definitely stands in the shadow of europa. Europa tells a story of a young German-American who wants to experience Germany just after the second world war. He takes a job that his uncle has arranged for him as a purser on a luxues train. Because of his job, he travels all through an almost totally destroyed germany, meeting with the killing of traitors, and hunt for former nazi party members. The society is suffering from corruption. His uncle has narrowed his conciousness by focussing on the job he has also as a purser on the train. By coincidence the main character get involved in bombing and terrorism by a group called 'werewolves' they put pressure on him to help them placing bombs on trains. The atmosphere is astounding. The viewer is taken from scene to scene by a man attempting to put the viewer under hypnosis and then counting to wake you up in a new scene. Just when you think you've seen a lot!!!!!!! europe!!\"\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in train_ds:\n",
    "    print(label_batch[0].numpy())\n",
    "    print(text_batch.numpy()[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d109c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "I read the comment of Chris_m_grant from United States.<br /><br />He wrote : \" A Fantastic documentary of 1924. This early 20th century geography of today's Iraq was powerful.\"<br /><br />I would like to thank Chris and people who are interested in Bakhtiari Nomads of Iran, the Zagros mountains and landscapes and have watched the movie Grass, A Nation's battle for life. These traditions you saw in the movie have endured for centuries and will go on as long as life endures. I am from this region of Iran myself. I am a Bakhtiari. <br /><br />Chris, I am sorry to bother you but Bakhtiari region of Zardkuh is in Iran not in Irak as you mentioned in your comment. Iran and Irak are two different and distinct countries. Taking an Iranian for an Irankian is almost like taking an American for an Mexican. Thanks,<br /><br />Ziba\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in train_ds:\n",
    "    print(label_batch[0].numpy())\n",
    "    print(text_batch.numpy()[0].decode('ascii'))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31b553d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7aa8a85a",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83546eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocal_size   = 20000\n",
    "sequence_len = 200\n",
    "\n",
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\n",
    "    return tf.strings.regex_replace(\n",
    "        stripped_html, f\"[{re.escape(string.punctuation)}]\", \"\"\n",
    "    )\n",
    "\n",
    "vectorization = tf.keras.layers.TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=vocal_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_len,\n",
    ")\n",
    "\n",
    "vectorization.adapt(train_ds.map(lambda text, label: text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974d6686",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e862776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text, label):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    return vectorization(text), label\n",
    "\n",
    "train_ds = train_ds.map(vectorize_text)\n",
    "val_ds = val_ds.map(vectorize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccf871ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[  280    43   457  1037   107    31     2   201    58    31     2   201\n",
      "   268     9    13    37   270    15    11   647    12    10    67  4890\n",
      "    42     2     1     5     2   134     3   199     9  1823   368    46\n",
      "   113    18     9     7    21     9     7    30   146     2    62     7\n",
      "   160   156    15     2    80     5     2  4434  2751   326  3058     9\n",
      "     1   708    20     2  8875     5     2    80    32  4899  1714     2\n",
      " 18710     2  4535     1     5     2    80    32  4149  1829  1072    20\n",
      "     2  1837   505     6     2   212    12     2  1242  1588  6270    41\n",
      "    54     2     1     1    32     2   166  1059  4751    36  1207    99\n",
      "   519     6 11394     2  4822    82   574     3  1597 16682    65 18015\n",
      "     4  7910  1902     8     2    19  4679    11    77    12    34   456\n",
      "     6    66     2  1873  6245    20     2  1837    30     5   128  6705\n",
      "    25    75   249     8     1  2837   862     8     2   751  3175   450\n",
      "    29   484    36    43  2377   447 18015     3  4183   989  2419    90\n",
      "    32     2  7702  1242    25    75  3981  3900   138     4     1     1\n",
      "  1714 11046     2     1     1     5     2  1242     8    61     4    52\n",
      "   662 19995     7  9678    32    33  1242  1484]\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in train_ds:\n",
    "    print(label_batch[0].numpy())\n",
    "    print(text_batch.numpy()[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c58c8da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[    2  1087     5  1028     5    11    17    43  4825     1   393    20\n",
      "     9    18    53    43     2   164  4194    14  2174  5284   116     8\n",
      "  1976   175     2    84   149    12   159    11    17   811    34    24\n",
      "   256     6  2487     4    17    16   280   175     8     9    15   673\n",
      "   225     5   261    71    25     6    25    11    17   786   180  3472\n",
      "  1188   329    12    24  7747    12   221     4   459   165   183     6\n",
      "   413     9    30   126  4678 12586     5   842  1836    17  2226     7\n",
      "     2   328     5    11  1227   417    19    29     4    49   598   827\n",
      "    15  4678     6    76    46   279   398     4  2229    17     8  3953\n",
      "    37    53   478    76 14866     8     2  1503   337    94    11   987\n",
      "    17     7    42    46   987   197    17    12    13   109  1689    81\n",
      "    11   987  1731  1110   304   175     8     9   450     2    17    64\n",
      "   406     6   472   843     2   459   205    62   352   362   254   110\n",
      "   461  4678    53  3045     2     1   120    53    11   827     7    40\n",
      "  1019    79   903     9    44    22   229    38  8782   599    41    40\n",
      "  1009     9    20     2  1893     5   122   702   387  1115    44    22\n",
      "    66     9    20     2  4287    89  5043     2]\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in val_ds:\n",
    "    print(label_batch[0].numpy())\n",
    "    print(text_batch.numpy()[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ff20dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a29080",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.cache().prefetch(buffer_size=10)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b062b100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b42a4eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
